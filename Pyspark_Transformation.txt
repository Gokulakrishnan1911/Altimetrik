6610c503620f9335369b16d5:~/environment $ pyspark
Python 3.9.16 (main, Sep  8 2023, 00:00:00) 
[GCC 11.4.1 20230605 (Red Hat 11.4.1-2)] on linux
Type "help", "copyright", "credits" or "license" for more information.
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/04/06 06:54:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/06 06:54:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.5.1
      /_/

Using Python version 3.9.16 (main, Sep  8 2023 00:00:00)
Spark context Web UI available at http://ip-10-0-3-80.ec2.internal:4041
Spark context available as 'sc' (master = local[*], app id = local-1712386472081).
SparkSession available as 'spark'.
>>> df=spark.read.format("csv").load("Employee_Details.txt")
>>> df.show()                                                                   
+-----------+--------------+-------+----------+
|        _c0|           _c1|    _c2|       _c3|
+-----------+--------------+-------+----------+
|Employee_ID| Employee_Name| Salary| Dept_Name|
|          1|         Gokul|  50000|     Sales|
|          2|           Ram|  99799|   Finance|
|          3|          Vels|  79999|     Sales|
|          4|        Ramesh|  10000|        IT|
|          5|       Boobesh|  15000|        IT|
|          6|       Adheesh|  10000|   Finance|
+-----------+--------------+-------+----------+

>>> df=spark.read.format("csv").option('header',true).load("Employee_Details.txt")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'true' is not defined
>>> df=spark.read.format("csv").option('header','true').load("Employee_Details.txt")
>>> df.show()
+-----------+--------------+-------+----------+
|Employee_ID| Employee_Name| Salary| Dept_Name|
+-----------+--------------+-------+----------+
|          1|         Gokul|  50000|     Sales|
|          2|           Ram|  99799|   Finance|
|          3|          Vels|  79999|     Sales|
|          4|        Ramesh|  10000|        IT|
|          5|       Boobesh|  15000|        IT|
|          6|       Adheesh|  10000|   Finance|
+-----------+--------------+-------+----------+

>>> df_bonus_salary=df.withColumn("Bonus_Salary", df[" Salary"]*2)                                                                                                                         
>>> df_bonus_salary.show()
+-----------+--------------+-------+----------+------------+
|Employee_ID| Employee_Name| Salary| Dept_Name|Bonus_Salary|
+-----------+--------------+-------+----------+------------+
|          1|         Gokul|  50000|     Sales|    100000.0|
|          2|           Ram|  99799|   Finance|    199598.0|
|          3|          Vels|  79999|     Sales|    159998.0|
|          4|        Ramesh|  10000|        IT|     20000.0|
|          5|       Boobesh|  15000|        IT|     30000.0|
|          6|       Adheesh|  10000|   Finance|     20000.0|
+-----------+--------------+-------+----------+------------+

>>> from pyspark.sql import *
>>> my_window= Window.partitionBy(" Dept_Name").orderBy(desc(" Salary"))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'desc' is not defined
>>> from pyspark.sql.functions import *
>>> my_window= Window.partitionBy(" Dept_Name").orderBy(desc(" Salary"))
>>> rank_result=df_1.withColumn("rank", dense_rank().over(my_window))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'df_1' is not defined
>>> rank_result=df_bonus_salary.withColumn("rank", dense_rank().over(my_window))                                                                                                           
>>> rank
rank(        rank_result  
>>> rank_result.show()
+-----------+--------------+-------+----------+------------+----+
|Employee_ID| Employee_Name| Salary| Dept_Name|Bonus_Salary|rank|
+-----------+--------------+-------+----------+------------+----+
|          2|           Ram|  99799|   Finance|    199598.0|   1|
|          6|       Adheesh|  10000|   Finance|     20000.0|   2|
|          5|       Boobesh|  15000|        IT|     30000.0|   1|
|          4|        Ramesh|  10000|        IT|     20000.0|   2|
|          3|          Vels|  79999|     Sales|    159998.0|   1|
|          1|         Gokul|  50000|     Sales|    100000.0|   2|
+-----------+--------------+-------+----------+------------+----+

>>> rank_result.filter(rank_result.rank==1).show()
+-----------+--------------+-------+----------+------------+----+
|Employee_ID| Employee_Name| Salary| Dept_Name|Bonus_Salary|rank|
+-----------+--------------+-------+----------+------------+----+
|          2|           Ram|  99799|   Finance|    199598.0|   1|
|          5|       Boobesh|  15000|        IT|     30000.0|   1|
|          3|          Vels|  79999|     Sales|    159998.0|   1|
+-----------+--------------+-------+----------+------------+----+

>>> rank_result.select(min(" Salary")).show()
+------------+
|min( Salary)|
+------------+
|       10000|
+------------+

>>> rank_result.select(max(" Salary")).show()                                                                                                                                              
+------------+
|max( Salary)|
+------------+
|       99799|
+------------+

>>> rank_result.select(sum(" Salary")).show()                                                                                                                                              
+------------+
|sum( Salary)|
+------------+
|    264798.0|
+------------+

>>> rank_result.withColumn("Overpaid", when(rank_result[" Salary"]>50000,'Y').otherwise('N')).show()
+-----------+--------------+-------+----------+------------+----+--------+
|Employee_ID| Employee_Name| Salary| Dept_Name|Bonus_Salary|rank|Overpaid|
+-----------+--------------+-------+----------+------------+----+--------+
|          2|           Ram|  99799|   Finance|    199598.0|   1|       Y|
|          6|       Adheesh|  10000|   Finance|     20000.0|   2|       N|
|          5|       Boobesh|  15000|        IT|     30000.0|   1|       N|
|          4|        Ramesh|  10000|        IT|     20000.0|   2|       N|
|          3|          Vels|  79999|     Sales|    159998.0|   1|       Y|
|          1|         Gokul|  50000|     Sales|    100000.0|   2|       N|
+-----------+--------------+-------+----------+------------+----+--------+

>>> rank_result.groupBy(" Dept_Name").agg(count("Employee_ID").alias("Employee_Count")).show()
+----------+--------------+
| Dept_Name|Employee_Count|
+----------+--------------+
|     Sales|             2|
|   Finance|             2|
|        IT|             2|
+----------+--------------+

>>> 